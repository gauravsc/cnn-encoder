import json
import torch
from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM


def prepare_minibatch_for_training(minibatch_data, tokenizer)
	
	



if __name__ == '__main__':

	# Load pre-trained model tokenizer (vocabulary)
	tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')







